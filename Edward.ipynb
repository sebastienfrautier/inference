{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Bayesian neural network using variational inference\n",
    "(see, e.g., Blundell et al. (2015); Kucukelbir et al. (2016)).\n",
    "Inspired by autograd's Bayesian neural network example.\n",
    "References\n",
    "----------\n",
    "http://edwardlib.org/tutorials/bayesian-neural-network\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import edward as ed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from edward.models import Normal, PointMass, Empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_toy_dataset(N=40, noise_std=0.1):\n",
    "  D = 1\n",
    "  X = np.concatenate([np.linspace(0, 2, num=N / 2),\n",
    "                      np.linspace(6, 8, num=N / 2)])\n",
    "  y = np.cos(X) + np.random.normal(0, noise_std, size=N)\n",
    "  X = (X - 4.0) / 4.0\n",
    "  X = X.reshape((N, D))\n",
    "  return X, y\n",
    "\n",
    "\n",
    "def neural_network(X):\n",
    "  h = tf.tanh(tf.matmul(X, W_0) + b_0)\n",
    "  h = tf.tanh(tf.matmul(h, W_1) + b_1)\n",
    "  h = tf.matmul(h, W_2) + b_2\n",
    "  return tf.reshape(h, [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ed.set_seed(42)\n",
    "\n",
    "N = 40  # number of data points\n",
    "D = 1   # number of features\n",
    "\n",
    "# DATA\n",
    "X_train, y_train = build_toy_dataset(N)\n",
    "\n",
    "# MODEL\n",
    "W_0 = Normal(loc=tf.zeros([D, 10]), scale=tf.ones([D, 10]))\n",
    "W_1 = Normal(loc=tf.zeros([10, 10]), scale=tf.ones([10, 10]))\n",
    "W_2 = Normal(loc=tf.zeros([10, 1]), scale=tf.ones([10, 1]))\n",
    "b_0 = Normal(loc=tf.zeros(10), scale=tf.ones(10))\n",
    "b_1 = Normal(loc=tf.zeros(10), scale=tf.ones(10))\n",
    "b_2 = Normal(loc=tf.zeros(1), scale=tf.ones(1))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [N, D])\n",
    "y = Normal(loc=neural_network(X), scale=0.1 * tf.ones(N))\n",
    "\n",
    "# INFERENCE\n",
    "qW_0 = Normal(loc=tf.Variable(tf.random_normal([D, 10])),\n",
    "              scale=tf.nn.softplus(tf.Variable(tf.random_normal([D, 10]))))\n",
    "qW_1 = Normal(loc=tf.Variable(tf.random_normal([10, 10])),\n",
    "              scale=tf.nn.softplus(tf.Variable(tf.random_normal([10, 10]))))\n",
    "qW_2 = Normal(loc=tf.Variable(tf.random_normal([10, 1])),\n",
    "              scale=tf.nn.softplus(tf.Variable(tf.random_normal([10, 1]))))\n",
    "qb_0 = Normal(loc=tf.Variable(tf.random_normal([10])),\n",
    "              scale=tf.nn.softplus(tf.Variable(tf.random_normal([10]))))\n",
    "qb_1 = Normal(loc=tf.Variable(tf.random_normal([10])),\n",
    "              scale=tf.nn.softplus(tf.Variable(tf.random_normal([10]))))\n",
    "qb_2 = Normal(loc=tf.Variable(tf.random_normal([1])),\n",
    "              scale=tf.nn.softplus(tf.Variable(tf.random_normal([1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior_post_mapping = {W_0: qW_0, b_0: qb_0,\n",
    "                     W_1: qW_1, b_1: qb_1,\n",
    "                     W_2: qW_2, b_2: qb_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 12s | Loss: 608.647\n"
     ]
    }
   ],
   "source": [
    "inference = ed.KLqp(prior_post_mapping, data={X: X_train, y: y_train})\n",
    "inference.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_post = ed.copy(y, prior_post_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Normal.variance of <ed.RandomVariable 'copied/Normal_2/' shape=(40,) dtype=float32>>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_post.variance\n",
    "ed.evaluate('log_likelihood', data={y_post: x_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input 0 of node copied/copied/MatMul was passed double from Const_8:0 incompatible with expected float.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d4ff596385a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0med\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_post\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/kbrusch/Desktop/_notebook/lib/python2.7/site-packages/edward/criticisms/evaluate.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(metrics, data, n_samples, output_key)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# different posterior sample. But it's expensive.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kbrusch/Desktop/_notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kbrusch/Desktop/_notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kbrusch/Desktop/_notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/kbrusch/Desktop/_notebook/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input 0 of node copied/copied/MatMul was passed double from Const_8:0 incompatible with expected float."
     ]
    }
   ],
   "source": [
    "print(ed.evaluate('mean_squared_error', data={X: X_train, y_post: y_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "q={\"a\": 1, \"b\":2}\n",
    "l={\"i\": 1, \"l\":2}\n",
    "ll = dict(q, **l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [100%] ██████████████████████████████ Elapsed: 94s | Acceptance Rate: 0.000\n"
     ]
    }
   ],
   "source": [
    "inference_HMC = ed.HMC([W_0, W_1, W_2, b_0, b_1, b_2], data={X: X_train, y: y_train})\n",
    "\n",
    "inference_HMC.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 8s | Loss: 111.985\n"
     ]
    }
   ],
   "source": [
    "inference_map = ed.MAP([W_0, W_1, W_2, b_0, b_1, b_2], data={X: X_train, y: y_train})\n",
    "\n",
    "inference_map.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = build_toy_dataset(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not copy instance: [[-1.        ]\n [-0.97368421]\n [-0.94736842]\n [-0.92105263]\n [-0.89473684]\n [-0.86842105]\n [-0.84210526]\n [-0.81578947]\n [-0.78947368]\n [-0.76315789]\n [-0.73684211]\n [-0.71052632]\n [-0.68421053]\n [-0.65789474]\n [-0.63157895]\n [-0.60526316]\n [-0.57894737]\n [-0.55263158]\n [-0.52631579]\n [-0.5       ]\n [ 0.5       ]\n [ 0.52631579]\n [ 0.55263158]\n [ 0.57894737]\n [ 0.60526316]\n [ 0.63157895]\n [ 0.65789474]\n [ 0.68421053]\n [ 0.71052632]\n [ 0.73684211]\n [ 0.76315789]\n [ 0.78947368]\n [ 0.81578947]\n [ 0.84210526]\n [ 0.86842105]\n [ 0.89473684]\n [ 0.92105263]\n [ 0.94736842]\n [ 0.97368421]\n [ 1.        ]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1c89c3a5da9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m x_post = ed.copy(X_train, {W_0: qW_0, b_0: qb_0,\n\u001b[1;32m      2\u001b[0m                      \u001b[0mW_1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqW_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqb_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                      W_2: qW_2, b_2: qb_2})\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# log-likelihood performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kbrusch/Desktop/_notebook/lib/python2.7/site-packages/edward/util/random_variables.pyc\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(org_instance, dict_swap, scope, replace_itself, copy_q)\u001b[0m\n\u001b[1;32m    153\u001b[0m   if not isinstance(org_instance,\n\u001b[1;32m    154\u001b[0m                     (RandomVariable, tf.Operation, tf.Tensor, tf.Variable)):\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not copy instance: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morg_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdict_swap\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not copy instance: [[-1.        ]\n [-0.97368421]\n [-0.94736842]\n [-0.92105263]\n [-0.89473684]\n [-0.86842105]\n [-0.84210526]\n [-0.81578947]\n [-0.78947368]\n [-0.76315789]\n [-0.73684211]\n [-0.71052632]\n [-0.68421053]\n [-0.65789474]\n [-0.63157895]\n [-0.60526316]\n [-0.57894737]\n [-0.55263158]\n [-0.52631579]\n [-0.5       ]\n [ 0.5       ]\n [ 0.52631579]\n [ 0.55263158]\n [ 0.57894737]\n [ 0.60526316]\n [ 0.63157895]\n [ 0.65789474]\n [ 0.68421053]\n [ 0.71052632]\n [ 0.73684211]\n [ 0.76315789]\n [ 0.78947368]\n [ 0.81578947]\n [ 0.84210526]\n [ 0.86842105]\n [ 0.89473684]\n [ 0.92105263]\n [ 0.94736842]\n [ 0.97368421]\n [ 1.        ]]"
     ]
    }
   ],
   "source": [
    "x_post = ed.copy(X_train, {W_0: qW_0, b_0: qb_0,\n",
    "                     W_1: qW_1, b_1: qb_1,\n",
    "                     W_2: qW_2, b_2: qb_2})\n",
    "\n",
    "# log-likelihood performance\n",
    "ed.evaluate('log_likelihood', data={x_post: X_train})\n",
    "\n",
    "#ed.ppc(inference_hmc, data={X:x_test, y:y_test}, latent_vars=None, n_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 40  # number of data points\n",
    "D = 1   # number of features\n",
    "\n",
    "# DATA\n",
    "X_train, y_train = build_toy_dataset(N)\n",
    "\n",
    "# MODEL\n",
    "W_0 = Normal(loc=tf.zeros([D, 10]), scale=tf.ones([D, 10]))\n",
    "W_1 = Normal(loc=tf.zeros([10, 10]), scale=tf.ones([10, 10]))\n",
    "W_2 = Normal(loc=tf.zeros([10, 1]), scale=tf.ones([10, 1]))\n",
    "b_0 = Normal(loc=tf.zeros(10), scale=tf.ones(10))\n",
    "b_1 = Normal(loc=tf.zeros(10), scale=tf.ones(10))\n",
    "b_2 = Normal(loc=tf.zeros(1), scale=tf.ones(1))\n",
    "\n",
    "X = tf.placeholder(tf.float32, [N, D])\n",
    "y = Normal(loc=neural_network(X), scale=0.1 * tf.ones(N))\n",
    "\n",
    "# INFERENCE\n",
    "qW_0 = Empirical(params=tf.Variable(tf.random_normal([D,10])))\n",
    "qW_1 = Empirical(params=tf.Variable(tf.random_normal([10,10])))\n",
    "qW_2 = Empirical(params=tf.Variable(tf.random_normal([10,1])))\n",
    "qb_0 = Empirical(params=tf.Variable(tf.random_normal([10])))\n",
    "qb_1 = Empirical(params=tf.Variable(tf.random_normal([10])))\n",
    "qb_2 = Empirical(params=tf.Variable(tf.random_normal([1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b2014bac2081>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m inference2 = ed.inference.HMC({W_0: qW_0, b_0: qb_0,\n\u001b[0m\u001b[1;32m      2\u001b[0m                      \u001b[0mW_1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqW_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqb_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                      W_2: qW_2, b_2: qb_2}, data={X: X_train, y: y_train})\n\u001b[1;32m      4\u001b[0m \u001b[0minference2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ed' is not defined"
     ]
    }
   ],
   "source": [
    "inference2 = ed.inference.HMC({W_0: qW_0, b_0: qb_0,\n",
    "                     W_1: qW_1, b_1: qb_1,\n",
    "                     W_2: qW_2, b_2: qb_2}, data={X: X_train, y: y_train})\n",
    "inference2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
